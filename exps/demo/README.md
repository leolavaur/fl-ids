# Demo: Challenging Federated Learning for Collaborative Intrusion Detection

Federated learning (FL) is a distributed machine learning paradigm enabling the training of global models without sharing the clients' data.
The "horizontal" settings is sometimes referred to as collaborative FL, as it allows participants to share locally-acquired knowledge with others.
This would allow IDSs to share insights while respecting the privacy and and confidentiality concerns of its organization.

In this demonstration, we show that (1) FL can improve the detection of locally unknown attacks using the others, (2) heterogeneous network topologies can impede the federation's performance, and (3) open federations are particularly sensitive to malicious actors.

## Repository Structure

The repository is structured as follows:
```bash
.
├── src/                    # Source code
│   ├── config.yaml         # Global config file
│   └── experiments/        # Experiments-specific configurations
│       ├── iid.yaml   
│       └── ...
├── results/                # Results, one directory per experiment
│   ├── iid/
│   │   ├── agg
│   │   │   ├── __main__.log    # Logs
│   │   │   ├── metrics.json    # Metrics generated by the experiment
│   │   │   ├── stats.json      # Statistics of the initial datasets
│   │   │   └── plot.png        # Plot of the default metric.
│   │   └── noagg
│   │       └── ...
│   └── ...
├── data/                   # Local copies of the datasets. They are not versioned.
├── flake.nix               # Nix file to build the project
├── flake.lock              # Lock file generated by nix
├── pyproject.toml          # Poetry requirement definitions
├── poetry.lock             # Poetry lock file
├── poetry.toml             # Poetry configuration
└── README.md               # This file
```
